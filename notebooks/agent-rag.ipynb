{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca29bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory root in the path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad063c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.extract_text import extract_text_from_svg\n",
    "\n",
    "complete_text = extract_text_from_svg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f1eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1º Tesoureiro\n",
      "Luiz Henrique Mendes Costa\n",
      "\n",
      "Semestre: 2º\n",
      "Gosta de:\n",
      "   animes\n",
      "manhwa\n",
      "games\n",
      "RPG\n",
      "cibersegurança\n",
      "curiosidades\n",
      "      tecnológicas\n",
      "\n",
      "henrique@ubuntu \n"
     ]
    }
   ],
   "source": [
    "for i,text in enumerate(complete_text):\n",
    "    if i < 6:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824bcb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complete_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b3a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=10,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "chunks = text_splitter.create_documents(complete_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "355231cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chunks: 115\n",
      "Chunk 1: len=13\n",
      "1º Tesoureiro\n",
      "Chunk 2: len=26\n",
      "Luiz Henrique Mendes Costa\n",
      "Chunk 3: len=96\n",
      "Semestre: 2º\n",
      "Gosta de:\n",
      "   animes\n",
      "manhwa\n",
      "games\n",
      "RPG\n",
      "cibersegurança\n",
      "curiosidades\n",
      "      tecnológicas\n",
      "Chunk 4: len=15\n",
      "henrique@ubuntu\n",
      "Chunk 5: len=13\n",
      "1º Secretário\n",
      "Chunk 6: len=24\n",
      "João Davi Costa de Souza\n"
     ]
    }
   ],
   "source": [
    "print(f'number of chunks: {len(chunks)}')\n",
    "\n",
    "for i,chunk in enumerate(chunks):\n",
    "    if i < 6:\n",
    "        print(f'Chunk {i+1}: len={len(chunk.page_content)}')\n",
    "        print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4020f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\":\"cpu\"}\n",
    ")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"../chroma_db\"\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa9a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 'What kind of environment does Yuri use?'\n",
      "Document 1 (Context):\n",
      "Yuri Gabriel Cardoso Delgado\n",
      "Document 2 (Context):\n",
      "Semestre: 2º\n",
      "Gosta de:\n",
      "   Tecnologia\n",
      "Estudar\n",
      "Séries\n",
      "Filmes\n",
      "Jogos\n",
      "Desenhos\n",
      "Environment:\n",
      "Hyprland (WM)\n",
      "Kitty (terminal)\n",
      "VS Code (Editor)\n",
      "Document 3 (Context):\n",
      "O Tesoureiro Geral, Yuri Delgado, e o Secretário Geral, Leonardo Brito, apesar dos compromissos e de outros dificultantes, também demonstraram interesse em participar.\n",
      "Document 4 (Context):\n",
      "Semestre: 2º\n",
      "Gosta de:\n",
      "Linux\n",
      "Ficção Científica\n",
      "Low-Level\n",
      "KPOP\n",
      "TRON\n",
      "Environment:\n",
      "Hyprland (WM)\n",
      "ST (terminal)\n",
      "Neovim (Editor)\n"
     ]
    }
   ],
   "source": [
    "query = \"What kind of environment does Yuri use?\"\n",
    "\n",
    "relevant_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"\\n '{query}'\")\n",
    "\n",
    "for i, doc in enumerate(relevant_docs):\n",
    "    if i < 6:\n",
    "        print(f\"Document {i+1} (Context):\")\n",
    "        print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a63bfc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "response: Lucas uses the following environment:\n",
      "*   **WM:** Hyprland\n",
      "*   **Terminal:** Kitty\n",
      "*   **Editor:** VS Code\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "#llm = OllamaLLM(model=\"llama3\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. Use the following context to answer the question.\n",
    "If you don't know the answer, say that you don't have enough information in the context.\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pergunta: {input}\n",
    "\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "query = \"Tell me What kind of environment does Lucas use?.\"\n",
    "\n",
    "response = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "print(f\"\\nresponse: {response['answer']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
